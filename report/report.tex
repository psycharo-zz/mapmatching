\documentclass[a4paper,twoside,11pt]{article}
\usepackage{a4wide,graphicx,fancyhdr,float,amsmath,amssymb,amsthm,ifthen,path,subfigure}
\usepackage{clrscode}
\usepackage{hyperref}
\usepackage{url}
\usepackage{color}
\usepackage{graphicx}
\usepackage{parskip}
\urlstyle{rm}

%\usepackage{algorithm2e}

%\usepackage[lined,boxed,commentsnumbered, ruled]{algorithm2e}
%% enable subfigures



%----------------------- Macros and Definitions --------------------------

\setlength\headheight{20pt}
\addtolength\topmargin{-10pt}
\addtolength\footskip{20pt}

\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\ch}{\ensuremath{\mathcal{CH}}}
\newcommand{\T}{\ensuremath{\mathcal{T}} }

\newcommand{\F}{F$_\varepsilon$}
\newcommand{\FD}{FD$_\varepsilon$}
\newcommand{\Lj}{\textbf{L}$_j$}
\newcommand{\Rj}{\textbf{R}$_j$}

\newcommand{\todo}{\textbf{TODO}}

\fancypagestyle{plain}{%
\fancyhf{}
\fancyfoot[LO,RE]{\sffamily\bfseries 2IL55~--~Geometrical Algorithms}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}

\pagestyle{fancy}
\fancyhf{}
% ----------------------------------------------------------------------------
% Insert your names here:
% ----------------------------------------------------------------------------
\fancyhead[LE]{\sffamily\bfseries Bagautdinov, Rong}
% ----------------------------------------------------------------------------
% Insert the title of your report here:
% ----------------------------------------------------------------------------
\fancyhead[RO]{\sffamily\bfseries Evaluation of Identical Machine Scheduling Algorithms}
%
\fancyfoot[LO,RE]{\sffamily\bfseries 2IL55~--~Geometrical Algorithms}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{0pt}

\theoremstyle{plain}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{fact}{Fact}
\theoremstyle{definition}  % switches off use of italics in following env's
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
% use \begin{proof}...\end{proof} for proofs (def'd in amsthm)

% set-up for algorithm2e
%\SetArgSty{}
%\setlength{\algomargin}{4ex}
%\SetKw{KwOr}{or}
%\SetKw{KwAnd}{and}
%\SetKw{KwReturn}{return}
%\SetKw{KwRequire}{Require:}
%\SetKw{KwInvariant}{Invariant:}
%\SetKwRepeat{KwRepeat}{repeat}{until}
%\dontprintsemicolon
% \linesnumbered

%-------------------------------- Title ----------------------------------

\title{
% ----------------------------------------------------------------------------
% Insert the title of your report here:
% ----------------------------------------------------------------------------
Evaluation of Map Matching Algorithms \\[1ex]
%
\large Research report for Geometrical Algorithms (2IL55) -- Spring semester 2012}

% ----------------------------------------------------------------------------
% Insert your names, student numbers, and email addresses here:
% ----------------------------------------------------------------------------
\author{
  \begin{minipage}[t]{.3\linewidth}
    \centering
    Timur Bagautdinov
  \end{minipage}
  \begin{minipage}[t]{.3\linewidth}
    \centering
    Zheyi Rong
  \end{minipage}
}

\hypersetup{%
  pdftitle={Evaluation of Map Matching Algorithms}, % title
  pdfauthor={Z.Rong, Bagautdinov},         % authors
  pdfborder={0 0 1},
  pdfcreator={}, pdfproducer={},
  citebordercolor={0 .667 0},          % dark green
  linkbordercolor={.5812 .0665 .0659}, % Indian red
  urlbordercolor={0 0 .667}            % dark blue
}

\date{\today}

%--------------------------------- Text ----------------------------------

\begin{document}

\maketitle

\begin{abstract}
%The purpose of this work is to investigate
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Navigational systems, particularly Global Positioning System (GPS), are very widely used nowadays,
especially for in-vehicle navigation.
One of the essential parts of in-vehicle navigational systems is \textit{map matching}. Map matching
is a process of identification the roads which the vehicle actually drives on based on its GPS trajectory.
This can be very important for applications involving different kinds of traffic analysis, like traffic jams predictioning
or driver behavior modeling.

There are some problems that make map matching a non-trivial task.
GPS receivers by themselves typically provide only very basic data.
Namely, what can be retrieved from such a receiver is a sequence of points - coordinates,
represented by longitude and latitude, and timestamps associated with these points.
This sequence of points, connected with straight line segments, defines the vehicle's moving trajectory,
which is to be linked with the road, usually modeled by a planar graph.
Generally, two types of inevitable errors associated with
the positioning data are signed out.

The first type, \textit{measurement errors}, are encountered due to GPS inaccuracy: different receivers, depending
on the weather conditions and the landscape (e.g. absence/presence of mountains and tall buildings),
can provide coordinates with the error from \textit{2m} up to \textit{8m}.

The second type of errors, \textit{sampling errors}, is caused
by the discrete nature of measurements, namely, the receiver only
gets position from satellites with a certain sampling rate, typically
a period lasting for several minutes.

In this work, we will provide an empirical evaluation of two map matching
algorithms: incremental algorithm (Section~\ref{sec:algorithms:incremental}) 
and a global algorithm based on \todo{Frechet distance}
(Section~\ref{sec:algorithms:frechet}).
The dataset and evaluation measures are described in Section~\ref{sec:experiment},
followed by Section~\ref{sec:results} with experimental results and discussions.




\section{Description of the algorithms}
\label{sec:algorithms}
% Description of the algorithms / data structures. In particular parts that you designed yourself
% should be explained in detail. You can also discuss implementation issues here or in a separate section.

There are two popular types of algorithms that are used to solve map matching problem
(\cite{Brakatsoulas:2005}).
The first one, called \textit{incremental matching}, it is a greedy-like strategy of extending
the current solution, based on various local geometrical settings, i.e. matching a part
of trajectory to the road paths considering different distance measures between curves, like
angles and euclidean distances. This approach, due to its local nature, is not expected
to produce the best possible solution, but is known be considerably fast.
(\cite{Lowsampling:2009}). %TODO: references

% TODO: references:p853-brakatsoulas,
The second type of matching algorithms, \textit{global matching}, involves comparison
of the whole trajectory with the curves representing the roads. This is usually accomplished
using some kind of curve similarity measure. One of the most widely used measures is \todo{Frechet distance},
which intuitively can be described as the minimum length of a leash needed to connect
a dog and its master, that walk on two distinct paths without backtracking.


\subsection{Incremental algorithm}
\label{sec:algorithms:incremental}
Incremental approach, given a timed sequence of vehicle positions $\{p_1,\ldots,p_n\}$
as an input, matches each of them one-by-one, starting with $p_1$.


\begin{figure}[ht!]
\label{fi:incremental:example}
\caption{Incremental map matching.}
 %\includegraphics{}
\end{figure}

Given that position $p_{i-1}$ is already matched, i.e. the corresponding edge $e_{i-1}$
from the road graph is already known, the algorithm indentifies a set of
\textit{candidate edges} as a set of edges, incident to $e_{i-1}$. Then,
candidate edges are evaluated using several similarity measures.
We are using the version with two following geometrical measures (\cite{Brakatsoulas:2005}).

Measure denoted as $s_d$ stands for the scaled distance from the position $p_i$ being
matched to the candidate edge $e_j$ and is computed as follows:
\[
 s_d(p_i, e_j) = \omega_d^{(1)} - \omega_d^{(2)} d(p_i, c_j),
\]
where $d$ is a distance between point and line segment, $\omega_d^{(1)}$ and $\omega_d^{(2)}$
are scaling factors.

Measure denoted as $s_{\alpha}$ represents the orientation of the moving trajectory,
computed based on the angle $\alpha$ between the directed part of the trajectory
$\overrightarrow{p_{i-1}p_i}$ and the candidate edge $e_j$ in the following way:
\[
 s_{\alpha}(p_i, e_j) = \omega_{\alpha} \cdotp \cos(\alpha),
\]
where $\omega_{\alpha}$ is a scaling factor.

The overall measure value is computed as the sum:
\[
s = s_d + s_{\alpha},
\]

and the edge with the maximum score is selected as the one that matches
the current position $p_i$ best.

\begin{figure}[ht!]
\label{fi:incremental:edge}
\caption{Incremental map matching. Projection cases.}
 %\includegraphics{}
\end{figure}


Due to sampling error, it might be the case, that the $p_i$ should not be
matched to any of the edges incident to the last matched edge. This
can be determined by checking whether $p_i$ projects on the endpoint of $e_j$ (case 1)
or on any point in-between (case 2). In the case 1, the algorithm
does not proceed to the next $p_i$, but instead tries to match incident edges of $e_j$ and
marks it as visited if it succeeds. In the case 2, the algorithm just matches
the edge if it has the best score out of all the candidates and proceeds
to the next point $p_{i+1}$.


\subsubsection*{Inititalisation}
To initialise the described algorithm, we need to match its initial position $p_1$. For that,
we need to determine the initial set of candidate edges that could match the directed part
of the trajectory $\overrightarrow{p_1 p_2}$.
This is done using the following simplistic approach: the edges are selected based on the threshold
distance to $p_1$. The particular threshold can be obtained from the learning dataset.
The k-d tree is used as an efficient datastructure for range searching (\cite{Berg:2009}).


\subsubsection*{Performance}
For every point of the tracking data $\{p_1,\ldots,p_n\}$,
we need to consider $m$ edges incident to the previously matched edge.
Here $m$ depends on the road network graph, which can be considered
as invariable. Hence, the running time of the algorithm will be of $O(n)$,
keeping in mind that initilisation depends only on the road graph.


\subsection{Global map-matching algorithm}
\label{sec:algorithms:frechet}

\subsubsection*{Distance measure}
	Firstly we introduce our distance meausure between a point $p$ and a segment $\overline{ab}$:
	\begin{equation}
		d(p, \overline{ab}) = \todo{projection on line or not}
	\end{equation}
	
\subsubsection*{Free space diagram}
	Suppose $\varepsilon = Max_error$ we have.
	We employ the notion of the \emph{free space} F$_\varepsilon$ and the free space diagram FD$_\varepsilon$
	of two curves, which was introduced in~\cite{alt:computing}. However, we simplify this notion, that is,
	call edges in the diagram free space, instead of the cells.
	\begin{definition}[free space and free diagram]
		by applying our distance measure, and LEFT RIGHT TOP BOTTOM
	\end{definition}
	
	\begin{figure}
		% figure of the definition
	\end{figure}

	
	Therefore, the map matching problem becomes : find a monotone path from a point to another point.

\subsubsection*{Construction}
	Instead of pre-calculating the free diagram of the whole ...
	we construct the free space diagram dynamically, i.e. while searching.
	
\subsubsection*{initilization}
	find some nodes within maxerror.
% 
% Our distance measures of two curves are based on the Frechet distance, which is defined as
% \[
%     \delta_F(f, g) := \inf_{^{\alpha:[0,1]\rightarrow I,}_{\beta:[0,1]\rightarrow J}} \max_{t\in [0,1]} \parallel f(\alpha(t)) - g(\beta(t))\parallel,
% \]
% where $f:I=[l_I,r_I]\rightarrow \mathbb{R}^2$, $g:J=[l_J,r_J]\rightarrow \mathbb{R}^2$ are two planar curves,
% $\parallel\cdot\parallel$ denotes the Euclidean norm, $\alpha$ and $\beta$ range over continuous and non-decreasing reparameterizations with $\alpha(0) = l_I, \alpha(1) = r_I, \beta(0) = l_J, \beta(1) = r_J$.
% 
% The curve and graph we will match are defined as following.
% Let $\alpha:[0,p]\rightarrow \mathbb{R}^2$ be a polygonal curve in $\mathbb{R}^2$, which consists of $p$ line segments $\overline{\alpha_i}:=\alpha|_{[i, i+1]}$ for $i\in \{0,1,...,p\}$.
% Let $G=(V,E)$ be an undirected connected planar graph with a given straight-line embedding in $\mathbb{R}^2$, $|V|=q$, $|E|=O(q)$
% such that $V={1,...q}$ corresponds to points ${v_1,...,v_q}\subset \mathbb{R}^2$.
% Though $G$ is an undirected graph, each each edge between vertices $i, j\in V$ is represented by the two directed edges $s_{i,j}, s_{j,i} \in E$. Besides, we denote the set of vertices adjacent to point $v_i \in V$ by Adj$(i)$.
% 
% With the definitions above, we formalize the matching problem: given $\alpha$ and $G$, find a path $\pi$ in $G$ which minimizes $\delta_F(\alpha, \pi)$.
% 
% To achieve this goal, we firstly solve the decision problem with $\varepsilon >0$ on whether there is a path in $G$ such that the Frechet distance is at most $\varepsilon$.
% Subsequently we apply parametric search to finally solve this minimization problem. Finally, we reconstruct the path with the help of the algorithm for the decision problem.
% 
% 
% \subsubsection*{Preprocessing}
% We employ the notion of the \emph{free space} F$_\varepsilon$ and the \emph{free space diagram} FD$\varepsilon$ of two curves $f$ and  $g$:
% the set F$_\varepsilon(f,g):=\{(s,t)\in I\times J | \parallel f(s) - g(t)\parallel \leq \varepsilon \}$.
% The \emph{free space diagram} FD$_\varepsilon(f,g)$ is the partition of $I\times J$ into regions belonging or not belonging to F$_\varepsilon(f,g)$.
% 
% The points in F$_\varepsilon$ are called \emph{white} or \emph{feasible}, and the ones in FD$_\varepsilon\backslash$F$_\varepsilon$ \emph{black} or \emph{infeasible}.
% 
% %% todo fig.1 insertion
% %% todo observation: the monotone curve in
% Furthermore, we define the \emph{free space} and the \emph{free space diagram} for edges and vertices.
% For every edge $(i,j)\in E$, consider the free space F$_{i,j}:=$\F$(\alpha, s_{i,j})\subset [0, p]\times[0,1]$.
% Then the free space diagram FD$_{i,j}=$\FD$(\alpha, s_{i,j})$ is the subdivision of $[0,p]\times[0,1]$ into the \emph{white} points of F$_{i,j}$ and the \emph{black} points of $[0,p]\times[0,1]\backslash$F$_{i,j}$.
% % todo: fig.2 as illustration
% 
% For a vertex $j\in V$, we define FD$_j:=$\FD$(\alpha, v_j)$, which is a one-dimensional free space diagram consisting of at most $2p+1$ black or white intervals. And, we define F$_j:=$\F$(\alpha, v_j)$ be the corresponding one-dimensional free space, which consists of a collection of white intervals. Besides, let \Lj be the left endpoint and \Rj be the right endpoint of FD$_j$.
% % till lemma 1
% 
% With these notions, we preprocess the curve and the graph as below for the decision problem.
% \begin{itemize}
%     \item For all $i \in V$ compute the one-dimensional free space diagrams FD$_i$.
%     \item For every $i\in V$ and every white interval $I$ of FD$_i$ compute for all $j\in$Adj$(i)$ the pointers $l_{i,j}(I)$ and $r_{i,j}(I)$ and store them in an array each, indexed by $j$.
% \end{itemize}
% 
% \subsubsection*{Dynamic programming and path reconstruction}
% In this subsection we decide whether there exists a feasible monotone path in the free space surface, from the result of preprocessing.
% 
% Firstly we initialize a queue $Q$ with all white \textbf{L}$_i$ for all $i\in V$, and $C_i$ for all $i\in V$, if \textbf{L}$_i$ is white we set $C_i:=$\textbf{L}$_i$, otherwise $C_i:=\emptyset$, where $C_i$ is a set of white points. We imagine a vertical sweep line sweeping from left to right, and $x$ is its current position.
% 
% Then we extract and delete the leftmost interval $I$ from $Q$; and advance $x$ to $l(I)$.
% 
% Afterwards we insert the next white interval of $C_i$ which lies to the right of $I$, into $Q$, where $C_i$ is the consecutive chain that contains $I$.
% 
% Subsequently for each $j\in$ Adj$(i)$ we update $C_j$ to comply with the new value of $x: [l_{i, j}(I), r{i,j}(I)]$ defines a consecutive chain on FD$_j$ which have now been identified to be reachable. We merge $[l_{i, j}(I), r{i,j}(I)]$ into $C_j$ together by simply considering the interval endpoints. If $l_{i,j}(I) > r(C_j)$ then we discard the old $C_j$ and replace it with $[l_{i, j}(I), r{i,j}(I)]$. If the left endpoint has change then we delete the old first interval of $C_j$ in $Q$ and insert the new one.
% 
% Finally we store for each white interval $J$ that has been newly added to $C_j$ (or that has been enlarged) a \emph{path pointer} to the interval $I$ (from which it can be reached by a monotone feasible path in FD$_{i,j}$).
% 
% We process all intervals in $Q$ until we either find a $j\in V$ such that \textbf{R}$_j\in C_j$, or until $Q$ is empty.
% 
% If from the dynamic programming stage, we found a $j\in V$ with \textbf{R}$_j\in J$, which means there is a path fulfilling the requirement: $\delta_F(\alpha, \pi) \leq \varepsilon$, we reconstruct this path as below.
% 
% We follow the path pointer created in the final step of dynamic programming to the right endpoint of an interval $I$, which is a suffix of an interval of FD$_i$ for an $i\in$Adj$(j)$. We repeat following the path pointers until we end at an \textbf{L}$_k$. This way we obtain a sequence of pairs $(i, r)$, where $i\in V$ and $r$ is the right endpoint of the visited interval on FD$_i$. We call this sequence the \emph{path sequence}. When we extract the first component of each pair, we obtain a sequence of $i\in V$ that represents the desired path $\pi$ in $G$. The corresponding feasible monotone path in \FD$(\alpha, \pi)$ can be constructed in an incremental way by following the path sequence and assuring monotonicity by using again a partial maxima stack of indices of lower spikes.
% 
% \subsubsection*{Distance measure}
% In this global matching algorithm, we used Frechet distance as distance measure of two curves, while other measures exist.
% 
% One slightly different measure is \emph{weak Frechet distance}, by dropping the requirement on $\alpha$ and $\beta$ to be non-decreasing in the definition of the Frechet distance.
% 
% Another different measure is \emph{average Frechet distance}. We approximate the \emph{integral Frechet distance}
% \[
% \delta_F^{int}(f, g) = \inf_{\alpha, \beta: [0,1]\rightarrow [0, 1]}\int_{(\alpha,\beta)} \parallel f(\alpha) - g(\beta) \parallel dt,
% \]
% by the \emph{sum Frechet distance} $\delta_F^{sum}(f, g)$
% \[
% \min_{P=(^\alpha_\beta)} \sum^{|P|}_{k=2}
%     \parallel f(i_{\alpha(k)}) - g(j_{\beta(k)}) \parallel
% \begin{Vmatrix}
%     \begin{pmatrix}
%         i_{\alpha(k)} - i_{\alpha(k-1)} \
%         j_{\beta(k)} - j_{\beta(k-1)}
%     \end{pmatrix}
% \end{Vmatrix},
% \]
% and normalize this sum distance by dividing by the arclength of the optimizing path
% \[
%    \sum^{|P|}_{k=2}
%    \begin{Vmatrix}
%     \begin{pmatrix}
%         i_{\alpha(k)} - i_{\alpha(k-1)} \
%         j_{\beta(k)} - j_{\beta(k-1)}
%     \end{pmatrix}
% \end{Vmatrix},
% \]
% called by the \emph{average Frechet distance}.


\section{Experimental setup}
\label{sec:experiment}
% TODO: Experimental setup: description of test data, aspects that you will investigate and possibly the hypotheses that you want to test.

\subsection*{Data}

The original data used is provided within GISCUP'12 competition on
map matching. The data consists of two parts: the road network and vehicle position tracking data.
The road network is represented by the road graph of Washington State with about
535,452 nodes and 1,283,540 edges.

The tracking data set contains positioning information for 10 vehicles. Both input and
output data is provided. Input is a set of vehicle positions, i.e. timestamp, longitude, latitude triples.
Output is the mapping from each vehicle position to the edge of the graph, representing the actual part of the road network
the vehicle was moving on.

% different sampling rates (the only thing we can change??)
From the dataset, we estimated that the average
sampling rate for every vehicle is identical and figures up to 1 second.
Based on the provided data, we also produced two more input datasets by modeling
sampling rates of 5, 10 and 15 seconds and a varying sampling rate (randomly uniformly
distributed from 1 to 10 seconds). This variable sampling rates are used to test the resiliency of
the algorithm to sparse GPS tracking data.

\subsection*{Measures}
% measures
The output of algorithms is a mapping from vehicle GPS positions
to corresponding edges, with the confidence of each match, where
the confidence is a real number in interval $(0;1]$.
The authors of the competition propose a compound measure
that incoroporates both the quality and running time.
Quality grade is initially set to zero, and then for each match it is increased by
a point weighted by confidence when the prediction is correct,
and decreased by the same number when the prediction is wrong.
The final measure is then obtained dividing quality grade by the running time.
Apart from the proposed measure, we are also using the quality grade
and the running time separately.


\section{Results and discussion}
\label{sec:results}
% TODO:  Results and discussion: presentation of the outcome of the tests, and discussion of the outcome.
% Here you also present the outcome of the data challenge for your algorithms (This can be simply a table)


\section{Conclusion}
\label{sec:conclusion}
% TODO: Conclusions: A very short summary of the most important results and the open problems / future research suggested by the results.



\bibliographystyle{alpha}
\bibliography{report}

\end{document}

